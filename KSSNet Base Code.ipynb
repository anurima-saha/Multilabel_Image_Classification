{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv  # PyTorch Geometric for GCN layers\n",
    "\n",
    "class CNNGCNModel(nn.Module):\n",
    "    def __init__(self, num_classes, label_graph_adj, cnn_output_dim=256, gcn_hidden_dim=128):\n",
    "        \"\"\"\n",
    "        Combines CNN and GCN for multi-label classification.\n",
    "        \n",
    "        Parameters:\n",
    "        - num_classes (int): Number of output labels/classes\n",
    "        - label_graph_adj (torch.Tensor): Adjacency matrix of the label graph\n",
    "        - cnn_output_dim (int): Dimensionality of CNN output features\n",
    "        - gcn_hidden_dim (int): Dimensionality of GCN hidden layer\n",
    "        \"\"\"\n",
    "        super(CNNGCNModel, self).__init__()\n",
    "        \n",
    "        # CNN Component (Example: simple CNN for feature extraction)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Input channels = 3 (RGB images)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, cnn_output_dim),  # Assuming input images are 32x32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # GCN Component\n",
    "        self.gcn1 = GCNConv(num_classes, gcn_hidden_dim)\n",
    "        self.gcn2 = GCNConv(gcn_hidden_dim, cnn_output_dim)\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classifier = nn.Linear(cnn_output_dim, num_classes)\n",
    "        \n",
    "        # Label graph adjacency matrix\n",
    "        self.label_graph_adj = label_graph_adj\n",
    "\n",
    "    def forward(self, x, label_features):\n",
    "        \"\"\"\n",
    "        Forward pass of the CNN-GCN model.\n",
    "        \n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Input image tensor [batch_size, 3, H, W]\n",
    "        - label_features (torch.Tensor): Initial label embeddings [num_labels, num_classes]\n",
    "        \n",
    "        Returns:\n",
    "        - logits (torch.Tensor): Predicted label scores [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # CNN forward pass\n",
    "        cnn_features = self.cnn(x)  # [batch_size, cnn_output_dim]\n",
    "        \n",
    "        # GCN forward pass\n",
    "        label_embeddings = self.gcn1(label_features, self.label_graph_adj)\n",
    "        label_embeddings = F.relu(label_embeddings)\n",
    "        label_embeddings = self.gcn2(label_embeddings, self.label_graph_adj)\n",
    "        label_embeddings = F.relu(label_embeddings)  # [num_labels, cnn_output_dim]\n",
    "        \n",
    "        # Combine CNN features and GCN label embeddings\n",
    "        logits = torch.matmul(cnn_features, label_embeddings.T)  # [batch_size, num_labels]\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "    num_classes = 10  # Number of labels/classes\n",
    "    cnn_output_dim = 256\n",
    "    gcn_hidden_dim = 128\n",
    "    batch_size = 32\n",
    "    img_size = 32  # Example image size (H=W=32)\n",
    "    \n",
    "    # Input data\n",
    "    x = torch.randn(batch_size, 3, img_size, img_size)  # Example RGB images\n",
    "    label_graph_adj = torch.eye(num_classes)  # Example: Identity adjacency matrix (no edges)\n",
    "    label_features = torch.eye(num_classes)  # Example: Identity matrix as initial embeddings\n",
    "    \n",
    "    # Initialize model\n",
    "    model = CNNGCNModel(num_classes, label_graph_adj, cnn_output_dim, gcn_hidden_dim)\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(x, label_features)\n",
    "    print(\"Logits shape:\", logits.shape)  # Expected: [batch_size, num_classes]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
